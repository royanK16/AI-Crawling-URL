# AI-Crawling-URL
## Tools I used
1) IDE : Visual Studio Code
2) GitHub
3) Front-End : Streamlit, BeautifulSoup
4) Back-End : Selenium, Pandas 
5) Language : Python
6) AI Model : Gemini--2.0 Flash
7) Deployment : Streamlit Cloud

## Conclusion
In this project, i mainly use the power of Gemini to crawl the data from the website, for people who do not know code can easily use my AI to crawl something they need. It works like a normal Generative AI(ChatGPT, DeepSeak, Gemini, Grok, ...). I store all my file code in GitHub, all libraries i used contained in requirements.txt, and packages.txt contains the driver of Google Chrome. 

I choose Streamlit and BeautifulSoup for my Front-End because it easily to use, Python support Selenium and Pandas very good so i choose it for my Back-End.
Finally, I deploy my model on Streamlit Cloud, it can connect directly to my reposity in GitHub so i can easily deploy my model.

## Instruction 
1> This is the main screen of model, you can enter the URL you want to crawl then click 'Scrape Site'
<img width="970" height="800" alt="image" src="https://github.com/user-attachments/assets/cb14d5d7-4651-4fb4-b8a5-cc4b2047013b" />

2> Waiting a moment until the "Scraping complete!" appears, then you can prompt what ever you want about from the website in the Description box.

3> Waiting until the Parsed Result appear, from there you can check the result again, you can prompt again if the result is not good.
<img width="889" height="835" alt="image" src="https://github.com/user-attachments/assets/551fffa1-2f13-421b-8fe8-839bee802578" />

4> Scroll down and click "Download Parsed Data as CSV" if you need, your screen will like this picture.
<img width="928" height="641" alt="image" src="https://github.com/user-attachments/assets/ee7a02bd-e1b8-4767-acee-340256544569" />



